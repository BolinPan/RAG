{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209d276a",
   "metadata": {},
   "source": [
    "# Query-Decomposition Retriever Demo\n",
    "\n",
    "The QueryDecompositionRetriever automates the process of prompt tuning by using an LLM to decompose a query into multiple sub-problems from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the MultiQueryRetriever can mitigate some of the limitations of the distance-based retrieval and get a richer set of results.\n",
    "\n",
    "## What this notebook contains\n",
    "- Decomposing a query into multiple sub-problems.\n",
    "- Retrieving documents for each sub-problem using a vector store (Chroma) and OpenAI embeddings.\n",
    "- Building a simple RAG pipeline that answers a question using either individually or recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a240d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  \n",
    "from langchain_community.document_loaders import WebBaseLoader  \n",
    "from langchain_community.vectorstores import Chroma  \n",
    "from langchain_core.output_parsers import StrOutputParser  \n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.load import dumps, loads\n",
    "from langchain import hub\n",
    "from operator import itemgetter\n",
    "import yaml\n",
    "import bs4  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090b5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Build the path to config.yaml\n",
    "config_path = os.path.join(cwd, '..', 'configs', 'config.yaml')\n",
    "\n",
    "# Normalize the path\n",
    "config_path = os.path.abspath(config_path)\n",
    "\n",
    "# Load credential from config file\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['LANGCHAIN_API_KEY'] = config['API']['LANGCHAIN']\n",
    "os.environ['OPENAI_API_KEY'] = config['API']['OPENAI']\n",
    "\n",
    "# Configure chat LLM (deterministic)\n",
    "llm = ChatOpenAI(temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8827d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loader that fetches and parses the target web page\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # tuple of URLs to load\n",
    "    bs_kwargs=dict(  # pass BeautifulSoup-specific kwargs to limit parsing\n",
    "        parse_only=bs4.SoupStrainer(  # only parse these parts of the page to reduce noise\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fetch and return a list of Document objects\n",
    "docs = loader.load()  \n",
    "\n",
    "# Split long documents into smaller overlapping chunks suitable for embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docs)  # list of smaller Document chunks\n",
    "\n",
    "# Create embeddings and store them in a vector DB (Chroma)\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())  # uses OpenAI embeddings under the hood\n",
    "\n",
    "# Create a retriever to fetch relevant docs (return the top 1 result)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9f2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask an LLM to decompose the question into multiple sub-questions\n",
    "template =\"\"\"\n",
    "You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\n",
    "\"\"\"\n",
    "\n",
    "# Build the prompt object\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Pipeline: prompt -> chat model -> parse -> split into separate queries\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))  # split on newlines into a list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4b9465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What is LLM technology and how does it work in autonomous agent systems?',\n",
       " '2. What are the specific components that make up an LLM-powered autonomous agent system?',\n",
       " '3. How do the main components of an LLM-powered autonomous agent system interact with each other to enable autonomous behavior?']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example input question\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "\n",
    "# decompose the question into multiple sub-questions\n",
    "result = generate_queries.invoke({\"question\":question})  \n",
    "\n",
    "# Display the generated variants\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24ba46f",
   "metadata": {},
   "source": [
    "##### Answer each sub-question individually via retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a50fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/7qg7n4m55nn6p0lx1w8bgmqh0000gn/T/ipykernel_60305/513804521.py:18: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(sub_question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: ['1. What is LLM technology and how does it work in autonomous agent systems?', '2. What are the specific components that make up an LLM-powered autonomous agent system?', '3. How do the main components of an LLM-powered autonomous agent system interact with each other to enable autonomous behavior?']\n",
      "Answers: ['LLM technology functions as the brain of autonomous agent systems. It works by being complemented by key components within the system.', \"The specific components that make up an LLM-powered autonomous agent system include LLM as the agent's brain, along with several key components.\", \"The main components of an LLM-powered autonomous agent system interact with LLM, which acts as the agent's brain. These components work together to enable autonomous behavior in the system. The key components complement LLM's functions to facilitate autonomous decision-making and actions.\"]\n"
     ]
    }
   ],
   "source": [
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
    "    \"\"\"\n",
    "    RAG on each sub-question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use our decomposition / \n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
    "        \n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \n",
    "                                                                \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries)\n",
    "print(f\"Questions: {questions}\")\n",
    "print(f\"Answers: {answers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92354bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main components of an LLM-powered autonomous agent system include LLM technology as the brain of the system, along with key components that work together to enable autonomous behavior. These components interact with LLM to facilitate autonomous decision-making and actions within the system.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"\n",
    "    Format Q and A pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Build the prompt object\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Compose pipeline: retrieval_chain -> prompt -> llm -> parse\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Execute the chain and get the answer\n",
    "final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08632a3",
   "metadata": {},
   "source": [
    "##### Answer each sub-question recursively via retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df541736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "recursive_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4091b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"\n",
    "    Format Q and A pair\n",
    "    \"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# Execute the chain and get the answer\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | recursive_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf069df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main components of an LLM-powered autonomous agent system interact with each other to enable autonomous behavior by working together in a coordinated manner. The LLM functions as the agent's brain, processing and generating human-like text to understand and respond to user inputs. This natural language processing capability allows the agent to communicate effectively with users. \\n\\nIn addition to the LLM, there are several key components that complement its functions within the system. These components may include modules for speech recognition, natural language understanding, dialogue management, and decision-making. Each component plays a specific role in the overall functioning of the autonomous agent system.\\n\\nThrough the interaction and collaboration of these components, the autonomous agent system is able to process user inputs, generate appropriate responses, make decisions based on the context of the conversation, and carry out tasks autonomously. This coordinated interaction enables the system to exhibit autonomous behavior by responding to user queries, engaging in meaningful conversations, and performing tasks without constant human intervention.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
